\chapter{Path Integrals and Quantum Dynamics} % Main chapter title

\label{Chapter4} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 4. \emph{Path Integrals and Quantum Dynamics}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened titl


\section{Introduction}

If we want to understand the electronic properties of materials, our limited understanding of analytically solvable quantum systems does not get us very far. There's only a limited number of systems with analytical solutions.

As in the case of classical mechanics, any realistic depiction of quantum systems would require understanding how the system couples with an environment, which influences it heavily. Open quantum system theory hence helps us with this problem since we can learn what happens to systems that interact with an environment and how that affects their dynamics. The easiest models of open quantum systems are called "system-bath" models where you have a (reasonably) solvable system coupled to a bath that represents the effects of an environment.

For studying electron-phonon systems, we need to construct models whereby we can understand what happens to the electrons when they interact with an ionic lattice as an environment. This chapter starts by covering the general theory of open quantum systems and the best ways to treat their evolution. We then move on to the path integral formulation and discuss how that helps us with the quantum dynamics of system-bath models. Once we have constructed these path integral equations, we move onto evaluating the path integrals using Monte Carlo simulations. 


\section{Dynamics of Open Quantum Systems}

For isolated quantum systems, the dynamics can be described by the time-dependent Schr{\"o}dinger equation (TDSE): \begin{equation}\label{4.1} -i\hbar \frac{\partial}{\partial t} \ket{\Psi(x, t)} = \mathcal{H} \ket{\Psi(x, t)}\end{equation}

The average values of a time-dependent observable A is given by \begin{equation} \label{4.2} A(t) = \bra{\Psi(t)} \hat{A} \ket{\Psi(t)} \end{equation}

One of our objectives is to figure out how a quantum-mechanical system moves from an initial state $t_0$ to a final state. A convenient tool to describe the states of macroscopic systems that can be formed from a mixture of pure states $\{ \Psi_{\nu} \}$ is the density operator $\hat{W}$, given by \begin{equation} \label{4.3} \hat{W} = \sum_{\nu} w_{\nu} \ket{\Psi_{\nu}} \bra{\Psi_{\nu}} \end{equation}which is a summation over the projection operators onto the pure states with a probability weight of $w_{\nu}$. Expectations for observables can now be determined by : $<\hat{A}> = Tr\{ \hat{W} \hat{A}\}$.

First let us try to construct an equation of motion for the density operator. 

\subsection{Liouville-von Neumann Equation}

John von Neumann extended the classical Lioville equation for phase space trajectories to quantum statistics.

The time propagation of the wavefunctions in eq. \ref{4.1} can be written as \begin{equation} \label{4.4} \ket{\Psi(t)} = U(t, t_0) \ket{\Psi(t_0)} \end{equation} where $$U(t, t_0) = \exp(-\frac{i \mathcal{H}(t - t_0)}{\hbar})$$.

We can substitute eq \ref{4.4} in in eq \ref{4.3} to obtain a time-dependent equation for the density operator.

\begin{equation} \label{4.5}
    \hat{W}(t) = \sum_{\nu} w_{\nu} U(t, t_0) \ket{\Psi(t_0)} \bra{\Psi(t_0)} U^{\dag}(t, t_0) = \sum_{\nu} U(t, t_0) W(t_0) U^{\dag}(t, t_0)
\end{equation}

To derive a time-derivative equation, take a partial derivative on both sides with respect to t:

\begin{equation} \label{4.6}
    \frac{\partial}{\partial t} \hat{W}(t) = -\frac{i}{\hbar}(\mathcal{H} \hat{W} - \hat{W} \mathcal{H}) = -\frac{i}{\hbar}[\mathcal{H}, \hat{W}(t)]
\end{equation}

Equation \ref{4.6} is called the Liouville-von Neumann equation and is the simplest equation for the evolution of macroscopic quantum systems. For brevity we can use the notation of super-operator $\mathcal{L} = \frac{1}{\hbar}[H, (.)]$ to get $$\frac{\partial}{\partial t} \hat{W} = -i \mathcal{L} \hat{W}$$

\subsection{System-Bath Models and The Reduced Density Matrix}

For models where we have a system coupled to a bath, we will represent our Hamiltonian in the form : 

\begin{equation} \label{4.7}
    \mathcal{H} = \mathcal{H}_S + \mathcal{H}_R + \mathcal{H}_{int}
\end{equation}

Where $\mathcal{H}_S$ is the Hamiltonian of the relevant system, represented only in terms of system coordinates $s = \{s_j\}$ and momenta $p = \{p_j\}$, $\mathcal{H}_R$ is the Hamiltonian of the reservoir having coordinates $Z = \{Z_{\xi}\}$ and momenta $P = \{P_{\xi}\}$. $\mathcal{H}_{int}$ is the linear coupling term of the system and the reservoir. 

For harmonic baths, the reservoir Hamiltonian reads $$\mathcal{H}_{R} = \sum_{\xi} \frac{P_{\xi}^2}{2M} + \frac{1}{2}M \omega_{\xi}^2$$

Since the system and bath are coupled, we cannot come up with a factorization scheme to separate the wavefunction out into system and bath co-ordinates. However, we can work out some kind of separation for the statistical operator.

Consider matrix elements of the statistical operator :

$$W(s, z ; s', z' ; t) = <s|(<Z|\hat{W}|Z'>)|s'>$$

If we want to write out a statistical operator in the state-space of the system co-ordinates alone, it would look like :

\begin{equation}
\rho(s, s' ; t) = \int dZ <s|(<Z|\hat{W}|Z'>)|s'>
\end{equation}

These can be considered as the matrix elements of a \emph{Reduced Density Operator} (RDO) :

\begin{equation}
    \hat{\rho}(t) = \int dZ \bra{Z}\hat{W}(t)\ket{Z} 
\end{equation}

This is a partial trace of the statistical operator over the reservoir coordinates. If we instead had a basis set $\{\ket{\alpha}\}$ that represented the reservoir states, we could write the RDO as:

\begin{equation}
    \hat{\rho}(t) = \sum_{\alpha} \bra{\alpha}\hat{W}(t)\ket{\alpha} = \Tr_{R}\{\hat{W}(t)\}
\end{equation}

The matrix elements of the RDO can be defined using any basis that represents the system. If $\ket{a}$ and $\ket{b}$ are members of a basis of the system state-space, we can get the relevent matrix element $\rho_{ab}$ by

\begin{equation}
    \rho_{ab}(t) = \bra{a}\hat{\rho(t)}\ket{b}
\end{equation}

This defines the elements of the Reduced Density Matrix (RDM).

If we have an electron interacting with a bath of harmonic modes with frequencies $\{\omega_i\}$, then we can abstract out the effect of this bath using the spectral density function \cite{maykuhn}:

\begin{equation}
    J(\omega) = \sum_{\xi} g_{\xi}^2 \delta(\omega - \omega_{\xi})
\end{equation}

Where $g_{\xi}$ is the coupling coefficient for each mode. 

\subsection{Quantum Master Equations}

\subsection{Adiabatic and Markov Approximations}

\section{Small Polaron Mobility from Hopping Rates}

% Write about Marcus hopping rate a bit here.

The Master Equation for Charge transport is :

\begin{equation}
\frac{dP_n}{dt} = \sum_{m \neq n} \Gamma_{mn} P_m(t) - \Gamma_{nm} P_n(t)
\end{equation}

Where $\Gamma_{mn}$ refers to the transfer rate (Adiabatic / Marcus hopping rate) and $P_n$ refer to the populations of the various sites. To get the populations of the sites at steady-state, we can reformulate this into a matrix equation :

\begin{equation}
    A_{mn} = \begin{cases} 
        \Gamma_{mn} & m\neq n \\
      -\sum_{m} \Gamma_{nm} & m = n \\ 
   \end{cases}
\end{equation}

Formulating this as a matrix equation :

\begin{equation}
    \boldsymbol{A} \vec{P} = 0
\end{equation}


Which can be solved by determining the nullspace of the matrix A. To do this, we perform a Singular Value Decomposition (SVD) of the matrix A:

\begin{equation}
    \boldsymbol{A} = \boldsymbol{U \Sigma V}^{T}
\end{equation}

See Appendix C for more on Singular Value Decompositions.

When computing the mobility of electrons under an electric field, we have to include the electric field into the Marucs hopping rate equation :

\begin{equation}
    \Delta E_{ij} = \epsilon_{i} - \epsilon_{j} - q \vec{F} . \vec{r}_{ij}
\end{equation}

Then, we use the Marcus hopping rate model to compute the elements of the matrix A  and find the populations of the states $P_m$ by performing an SVD on the matrix A. Here $\vec{r}_{ij}$ is the displacement vector from site i to site j.

From the rates and the occupation probabilities, we can determine the average velocity of charges:

\begin{equation}
\vec{v} = \sum_{m \neq n} \vec{r}_{mn} A_{mn} P_n 
\end{equation}

Then we can get the mobility using 
\begin{equation}
\mu = \frac{<v>}{F}
\end{equation}

Where $<v>$ is the average velocity in the direction of the field and F is the magnitude of the field.
 
\section{Path Integral Treatment of Open Quantum Systems}

% Why are path integrals useful for treating quantum systems.
% S + R  => Influence Functionals.


For a general Hamiltonian in cartesian co-ordinates $$\mathcal{H} = \sum_{j} \frac{p_j^2}{2m_j} + V(x_1, ..., x_n)$$

To propagate this system from an initial ($t_0$, $x_0$) to a final ($t_f$, $x_f$), let us split the time scale t into N short time chunks $\Delta t \equiv \frac{t}{N}$. Now the time-evolution operator can be written as :

\begin{equation} \label{4.x}
    e^{-i\mathcal{H}t/\hbar} = e^{-i\mathcal{H}\Delta t/\hbar}...e^{-i\mathcal{H}\Delta t/\hbar} = \prod_{k=1}^{N} e^{-i\mathcal{H}(t_k - t_{k-1})/\hbar}
\end{equation}

where $t_k = kt/N$. 

Using $$\int dx_k \ket{\psi_k}\bra{\psi_k} = 1$$ between successive steps we get :

\begin{equation} \label{4.xx}
    \bra{x_f} e^{-i\mathcal{H}t/\hbar} \ket{x_0} = \int dx_1 ... \int dx_{N-1} \prod_{k=1}^{N} \bra{x_k} e^{-i\mathcal{H}(t_k - t_{k-1})/\hbar} \ket{x_{k-1}}
\end{equation}

This is an exact representation for any value of N. $x_f \equiv x_N$ is the final point in the  propagation.

To evaluate this integral, we need an approximation to evaluate the short time propagator in a time-step $\Delta t$. If operators A and B do not commute, we cannot use the rule of exponential of a sum of operators equals the product of exponentials of the operators. The expansion of $e^{A+B}$ developed by Suzuki and Trotter \cite{trotter1959} helps us alleviate this problem. They found that :

\begin{equation}\label{4.x}
e^{\delta(A + B)} = e^{\delta A}e^{\delta B} + O(\delta^2)
\end{equation}

The error term $O(\delta^2)$ vanishes when we take the limit of $\delta \to 0$.

As a guess way to split the Hamiltonian if we separate out the kinetic term $\mathcal{T}$ and the potential term $\mathcal{V}$ in the following way :

\begin{equation}\label{4.x}
e^{-i\mathcal{H}\Delta t/\hbar} \approx e^{-i\mathcal{V}\Delta t/2\hbar}e^{-i\mathcal{T}\Delta t/\hbar}e^{-i\mathcal{V}\Delta t/2\hbar} 
\end{equation}

We can evaluate the kinetic part exactly to get :

\begin{equation} \label{4.x}
\bra{x_k}e^{-i\mathcal{H} \Delta t/\hbar}\ket{x_{k-1}} = \prod_{j=1}^{n} (\frac{m_j}{2\pi i \hbar \Delta t})^{1/2} \exp(\frac{i}{\hbar} \frac{m_j}{2\Delta t} (x_{j,k} - x_{j, k-1})^2)
\end{equation}

Plugging this into the propagation expression we get :

\begin{equation} \label{4.x}
    \begin{split}
        \bra{x_f} e^{-i\mathcal{H}t/\hbar} \ket{x_0} & \approx \prod_{j=1}^{n} (\frac{m_j N}{2\pi i \hbar t})^{1/2}  \int d^n x_1 ... \int d^n x_{N-1} \\ & \exp(\frac{i}{\hbar} \sum_{k=1}^{N} (\sum_{j=1}^{n} \frac{m_j N}{2t} (x_{j,k} - x_{j, k-1})^2 - \frac{t}{2N}[\mathcal{V}(x_k) + \mathcal(V_{k-1})]))
    \end{split}
\end{equation}

This equation is the "primitive" discretized path integral expression. As we use more sophisticated methods to split the Hamiltonian we will get better discretized expressions to work with.

When we take the limit of $N \to \infty$, we get an equality.  

\begin{equation}
    \bra{x_f} e^{-i\mathcal{H}t/\hbar}\ket{x_0} = \int \mathcal{D}x \exp(\frac{i}{\hbar} S[x])
\end{equation}

Where $S[x]$ is the action functional $\int \mathcal{L}[x, t] dt$ of the path. This is the well-known Feynman path integral expression. \cite{feynhibbs} We will however be dealing with discretized path integral expressions to understand the dynamics of systems we're interested in.

We cannot use monte carlo methods to sample the primitive discretization of the path integral since it is a highly oscillatory function. Typically the phase terms cancel each other out dramatically in this oscillating function and Monte carlo schemes carried over long time periods fail to capture all the information necessary. This is called the Monte carlo "sign problem".

We take three approaches to try and deal with this. The first is to substitute the time term with another variable so that the phase factor (and consequently the integrand) becomes real. The second approach is to use a better Trotter splitting scheme to generate well-behaved propagators to simulate long time dynamics. The third uses a method from complex analysis known as "analytic continuation" to determine the observables of interest.

\section{Imaginary Time Path Integral Monte-Carlo}

This is the first of the approaches we take to tackle the sign problem that arises in evaluating path integrals using monte carlo simulations. 

To get the integrand to stop oscillating, we have to make the phase factor a real number. We do this by what is called a "Wick Rotation". By substituting time with imaginary time, we solve the problem of the phase factor being an imaginary number. Using $\beta = it/\hbar$, convert the phase term to $\exp(-\beta \mathcal{H})$. This is the standard expression for a system at thermal equilibrium (canonical ensemble) \cite{tuckerman2023statistical}. Discretized path integrals handle many-body problems at thermal equilibrium very well because they can be solved easily in imaginary time.

\section{Real Time Path Integral Dynamics}

One of the major issues with performing real-time path integral monte carlo simulations is the infamous sign problem, as mentioned earlier. 
To alleviate the sign problem, we employ a method developed by Makri and co-workers \cite{quapi} to develop equations that converge when attempting to numerically sample discretized path integral expressions using Monte Carlo simulations.

\subsection{Quasi-Adiabatic Propagator Path Integral (QuAPI)}

 If we instead performed the Trotter decomposition as such : 
 \begin{equation}
\mathcal{H} = \mathcal{H}_{ref} + \mathcal{H}_{int}
 \end{equation}

Where $\mathcal{H}_{ref}$ can be decomposed into solvable 1-D or 2-D systems ($\mathcal{H}_0$) 

Then apply Trotter splitting : 

\begin{equation}
e^{-i \mathcal{H} \Delta t /\hbar} \approx e^{-i\mathcal{H}_{int}\Delta t / 2\hbar}e^{-i\mathcal{H}_{ref}\Delta t / \hbar}e^{-i\mathcal{H}_{int}\Delta t / 2\hbar}
\end{equation}

The step-wise propagator elements become:

\begin{equation}
\bra{x_k}e^{-i \mathcal{H} \Delta t / \hbar} \ket{x_{k-1}} = \bra{x_k}e^{-i \mathcal{H}_{ref} \Delta t / \hbar}\ket{x_{k-1}}  \exp(\frac{-i \Delta t}{2 \hbar}(\mathcal{H}_{int}(x_k) + \mathcal{H}_{int}(x_{k-1})))
\end{equation}

This is called the \emph{Quasi-Adiabatic Propagator}.

Since $\mathcal{H}_{ref}$ can be decomposed to a set of solvable 1D or 2D problems $\mathcal{H}_0$, we will assume that we have these solutions in hand when carrying out the monte carlo computation of the dynamics.


If the eigenvalues of $\mathcal{H}_0$ are $E_m$ and the eigenvectors are $\Phi_m$, then :

\begin{equation}
\bra{x_k}e^{-i \mathcal{H}_{0} \Delta t / \hbar}\ket{x_{k-1}} = \sum_{m}^{m_{max}} \Phi_m (x_k) \Phi_m(x_{k-1}) e^{-iE_{m}\Delta t / \hbar}
\end{equation}

For a finite value of $m_{max}$ we get converging solutions of the effective propagator.

Now we can propagate the reduced density matrix elements over time :

\begin{equation}
\begin{split}
\rho(s, s', t) = & \int ds_0^{+} \int ds_1^{+} ... \int ds_{N-1}^{+} \int ds_{0}^{-} ... \int ds_{N-1}^{-} \\ &  <s'|e^{-i \mathscr{H}_{0} \Delta t / \hbar}|s_{N-1}^{+}> ... <s_1^{+}|e^{-i \mathscr{H}_{0} \Delta t / \hbar}|s_0^{+}> \\ & <s_0^{+}|\rho(0)|s_0^{-}> <s_0^{-}|e^{-i \mathscr{H}_{0} \Delta t / \hbar}|s_1^{-}> ...<s_{N-1}^{-}|e^{-i \mathscr{H}_{0} \Delta t / \hbar}|s>F(s', s, s_i^{+}, s_i^{-} ; \Delta t)
\end{split}
\end{equation}

This is the Quasi-Adiabatic Propagator Path Integral (QuAPI) expression. Here $F$ represents the influence functional, capturing the effect of the reservoir \cite{feynman2000theory}. 

To sample the grid points, we perform a Monte Carlo random walk over a 2N dimensional grid, since we integrate over 2N dimensions considering both the forward and backward paths 

\subsection{Quantum-Classical Path Integral (QCPI)}

One way to help treat a system with a large number of degrees of freedom is to provide a classical description of the environment degrees of freedom (which emerge when there is large decoherence) \cite{makri2015quantum}. 

We can re-write the open system Hamiltonian as a function of quantum mechanical system states and a classical phase space of the environment:

\begin{equation}
\mathcal{H} = \mathcal{H}_S(\hat{s}, \hat{p_s}) + \mathcal{H}_R(\mathbf{q}, \mathbf{p}) + \mathcal{H}_{int}(\hat{s}, \mathbf{q})
\end{equation}

Where $\hat{s}$ and $\hat{p_s}$ represent the quantum-mechanical system coordinate and positions, while \textbf{q} and \textbf{p} represent vectors of position and momenta degrees of freedom of a classical environment phase space.

For the reduced density matrix (RDM), we write the quasi-adiabatic propagator path integral as:

\begin{equation}
    \rho(s_N^{+-}, t) = \int ds_{0}^{+-} ... \int ds_{N-1}^{+-} K_0(s_N^{+}, s_{N-1}^{+}) ... K_0(s_1^{+}, s_0^{+}) \rho(s_0^{+-}, 0)K_0(s_0^{-}, s_1^{-})...K_0(s_{N-1}^{-}, s_N^{-}) F(s_0^{+-}...s_N^{+-})
\end{equation}

For the QCPI representation we use the influence functional $F_{class}$ corresponding to a classical trajectory of the environment, starting from an initial $\mathbf{q_0}$, $\mathbf{p_0}$ :

\begin{equation}
    F_{class} = \int d\mathbf{q_0} \int d\mathbf{p_0} P(\mathbf{q_0}, \mathbf{p_0}) \exp(\frac{i}{\hbar} \Phi_{env}(\mathbf{q_0}, \mathbf{p_0}, s))
\end{equation}

Where P is the phase space density and $\Phi_{env}$ is the net forward-backward action for the path integral.

For a system coupled to a harmonic bath with a linear coupling term, we can write the influence function as: 

\begin{equation}
    F = \exp[\frac{-1}{\hbar} \int_0^{t} dt' \int_{0}^{t'} dt'' (s^+(t') - s^-(t'))][\alpha(t' - t'')s^+(t'') - \alpha(t' - t'')^{*}s^-(t'')]
\end{equation}

Where the $\alpha$ function is a force auto-correlation of the bath. 

For the classical trajectory, we use the solution of a classical forced harmonic oscillator :

\begin{equation}
    q_j(t) = q_{j,0}\cos(\omega_j t) + \frac{p_{j,0}}{m_j \omega_j} \sin(\omega_j t) + \frac{c_j}{2 m_j \omega_j} \int_0^{t} dt' \bar{s}(t')\sin(\omega_j)(t-t')
\end{equation}

Where $c_j$ is the linear coupling term and $\bar{s} = \frac{1}{2}(s^+ + s^-)$ 

\subsection{Evaluating the Real-Time Path Integrals}

\subsection{Determining Observables}

\subsubsection{Mobility}

For determining the mobility of the polarons in these systems we use the Einstein-Smoluchowski relation : 

\begin{equation}
    \mu = \beta qD
\end{equation}

Where $\mu$ is the mobility, q is the charge, D is the diffusion coefficient and $\beta = \frac{1}{k_B T}$. 

For getting the mobility we use a method developed by Blumberger and co-workers \cite{blumberger} 

The diffusion coefficient can be got from the Mean Square Displacement (MSD) as follows: 

\begin{equation}
D = \frac{1}{2} \lim_{t \to \infty} \frac{dMSD}{dt}
\end{equation}

In the diffusive regime, the MSD is a linear function of time, so we simply take the slope of MSD vs t calculations for calculating mobility.

There are multiple definitions for how to compute the MSD for quantum dynamics simulations but we have chosen to use the following:

\begin{equation}
    MSD(t) = \sum_{k=1}^{M} P_{k}(t) (x_{k}(t) - x(0))^2
\end{equation}

Here, $P_k(t) = \rho_{kk}$ is the population of site k at time t. This calculation of MSD is typically averaged over multiple simulations of the dynamics calculation.

\subsubsection{Polaron Radius}

\subsubsection{Self-Energy}

\section{Analytic Continuation Method}

We can also obtain the mobility of polarons using a combination of imaginary and (short) real time path integral monte carlo simulations using an analytic continuation \cite{miladic2023method}. 

 The Holstein polaron Hamiltonian for an electron coupled to phonon modes in a lattice is given by:

 \begin{equation}
    \mathcal{H} = \sum_n [-J(c_n^{\dag} c_{n+1} + c_{n+1}^{\dag}c_{n}) + (\frac{P_n^{2}}{2M} + \frac{1}{2}M\omega_n^{2} Z_{n}^{2}) + g_n c_n^{\dag}c_n Z_n]
 \end{equation}

 Where $c_n$ and $c_{n+1}$ represent the annihilation operators in second-quantization representation for electrons at lattice sites n and n+1 respectively.

 We can split this as $\mathcal{H} = \mathcal{H}_0 + \mathcal{H}_1 + \mathcal{H}_2$ where $\mathcal{H}_2$ is the first term representing electron energies, $\mathcal{H}_0 = \sum_n \frac{P_n^2}{2M}$ and $\mathcal{H}_1$ contains the other terms.

 The DC mobility $\mu$ is given by the Kubo formula :

 \begin{equation}
    \mu = \frac{\beta}{2} \int_{-\infty}^{\infty} dt<j(t)j(0)>
 \end{equation}

Where j is the current density operator. 

For two arbitrary operators A and B the time-correlation function (TCF) is given by :

\begin{equation}
<A(t)B> = Z^{-1} \Tr[e^{-\beta \mathcal{H}} e^{it\mathcal{H}}Ae^{-it\mathcal{H}}B]
\end{equation}

If we split $beta$ into m intervals ($\tau = \beta/m$) and $t$ into Q intervals ($t= \Delta t/Q$) and perform a Suzuki-Trotter decomposition of the Hamiltonian based on the splitting mentioned earlier, we can write the TCF as :

\begin{equation}
<A(t)B> = Z^{-1} \Tr[(e^{-\tau \mathcal{H}_0}e^{-\tau \mathcal{H}_1}e^{-\tau \mathcal{H}_2})^m (e^{i\Delta t\mathcal{H}_0}e^{it\mathcal{H}_1}e^{i\Delta t\mathcal{H}_2})^QA(e^{-i \Delta t \mathcal{H}_0}e^{-i \Delta t \mathcal{H}_1}e^{-i \Delta t \mathcal{H}_2})^QB]
\end{equation}

If we consider the basis states to be a direct product of electron momenta and phonon coordinates :

\begin{equation}
    \ket{k;\{X\}} = \ket{k}\ket{X_1}\ket{X_1}...\ket{X_{N}}
\end{equation}

We can derive a path integral expression for the TCF and sample it using Monte carlo calculations performed over both a short real time t and over imaginary time.

To get the mobility, we construct the inverse equation of the current density TCF :

\begin{equation}
    <j(t_c)j(0)> = \int_{-\infty}^{\infty} d \omega \frac{1}{\pi} \frac{\omega e^{-i\omega t_c}}{1 - e^{-\beta \omega}} Re \mu(\omega)
\end{equation}

Where $t_c$ represents both the imaginary time $t_c = -it$ where $0 \leq t \leq \beta$ and short real times $t_c = t$.

To perform the analytic continuation, we first discretize this integral equation :

\begin{equation}
\textbf{j} = \textbf{K . m}
\end{equation}

Where \textbf{j} represents the discretized current density TCF elements in real and imaginary time. \textbf{m} is the discretized representation of the real part of the mobility. \textbf{K} is a linear operator that takes care of the integral term. We need to get \textbf{m}, knowing \textbf{K} (from discrete fourier transforms) and \textbf{j} (from the real and imaginary time monte carlo calculations). We get \textbf{m} by performing a Singular Value Decomposition of \textbf{K} (see Appendix C) and using the factors to derive the elements of \textbf{m}. 







